Урок 3. Построение модели классификации.




Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?


micro — расчет метрики на глобальном уровне путем подсчета итоговых истинных положительных результатов, ложноотрицательных и ложноположительных результатов (независимо от классов). В случае с F1, по-сути, получаем accuracy.

macro  — вычисление метрики для каждого класса и получение невзвешенного среднего.  

weighted — вычисление метрик для каждого класса и получение взвешенного среднего по числу выборок на каждый класс.

Хотя каждый метод усреднения имеет свои преимущества, одним из общих соображений при выборе соответствующего метода является дисбаланс классов. Если у классов разное количество выборок, более информативным может быть использование макроусреднения, при котором классам меньшинства и большинства назначается одинаковый вес.

В мультиклассовой классификации предпочтение отдается микро-среднему, если вы подозреваете, что может быть дисбаланс классов (т.е. у вас может быть гораздо больше примеров одного класса, чем других классов)








В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?

CatBoost
CatBoost обладает гибкостью, позволяя задавать индексы категориальных столбцов, чтобы его можно было кодировать как кодирование в одно касание с использованием one_hot_max_size (используйте кодирование в одно касание для всех функций с числом различных значений, меньшим или равным данному значению параметра).

Если вы ничего не передаете в аргументе cat_features, CatBoost будет обрабатывать все столбцы как числовые переменные.



LightGBM
Как и в CatBoost, LightGBM также может обрабатывать категориальные функции, вводя имена функций. Он не конвертируется в одноразовое кодирование и намного быстрее, чем одноразовое кодирование. LGBM использует специальный алгоритм, чтобы найти значение разделения категориальных признаков.



XGBoost
В отличие от CatBoost или LGBM, XGBoost не может обрабатывать категориальные функции сам по себе, он принимает только числовые значения, подобные случайному лесу. Поэтому перед подачей категориальных данных в XGBoost необходимо выполнить различные кодировки, такие как кодирование меток, среднее кодирование или однократное кодирование.








